{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ae3200-e772-477d-908d-dcbbc66dafda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8486fdbb-5367-4ff2-9c80-61acb96f971f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-02-07 16:34:46,497] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.artist.tokenizer.ArtistTokenizer'> to load 'pai-painter-painting-base-zh'.\u001b[0m\n",
      "\u001b[32m[2023-02-07 16:34:46,498] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/artist/pai-painter-painting-base-zh/vocab.txt and saved to C:\\Users\\Administrator\\.paddlenlp\\models\\pai-painter-painting-base-zh\u001b[0m\n",
      "\u001b[32m[2023-02-07 16:34:46,609] [    INFO]\u001b[0m - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/artist/pai-painter-painting-base-zh/vocab.txt\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 107k/107k [00:00<00:00, 1.06MB/s]\n",
      "\u001b[32m[2023-02-07 16:34:46,948] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\Administrator\\.paddlenlp\\models\\pai-painter-painting-base-zh\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-02-07 16:34:46,950] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\Administrator\\.paddlenlp\\models\\pai-painter-painting-base-zh\\special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2023-02-07 16:34:46,951] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.artist.modeling.ArtistForImageGeneration'> to load 'pai-painter-painting-base-zh'.\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "configuration file<config.json> or <model_config.json> not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_to_image \u001b[38;5;241m=\u001b[39m \u001b[43mTaskflow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_to_image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m image_list \u001b[38;5;241m=\u001b[39m text_to_image(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m风阁水帘今在眼，且来先看早梅红\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m image_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpainting-figure-1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\taskflow\\taskflow.py:590\u001b[0m, in \u001b[0;36mTaskflow.__init__\u001b[1;34m(self, task, model, mode, device_id, from_hf_hub, **kwargs)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m    589\u001b[0m task_class \u001b[38;5;241m=\u001b[39m TASKS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask][tag][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_class\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_instance \u001b[38;5;241m=\u001b[39m task_class(\n\u001b[0;32m    591\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask, priority_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriority_path, from_hf_hub\u001b[38;5;241m=\u001b[39mfrom_hf_hub, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m    592\u001b[0m )\n\u001b[0;32m    593\u001b[0m task_list \u001b[38;5;241m=\u001b[39m TASKS\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    594\u001b[0m Taskflow\u001b[38;5;241m.\u001b[39mtask_list \u001b[38;5;241m=\u001b[39m task_list\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\taskflow\\text_to_image.py:60\u001b[0m, in \u001b[0;36mTextToImageGenerationTask.__init__\u001b[1;34m(self, task, model, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_fp16_decoding \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_fp16_decoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_tokenizer(model)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\taskflow\\text_to_image.py:66\u001b[0m, in \u001b[0;36mTextToImageGenerationTask._construct_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_construct_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Construct the inference model for the predictor.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForImageGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\auto\\modeling.py:1053\u001b[0m, in \u001b[0;36mAutoModelForImageGeneration.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03m    Creates an instance of `AutoModelForImageGeneration`. Model weights are loaded\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;124;03m    by specifying name of a built-in pretrained model, or a community contributed model,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;124;03m            # <class 'paddlenlp.transformers.dallebart.modeling.DalleBartForImageGeneration'>\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\auto\\modeling.py:297\u001b[0m, in \u001b[0;36m_BaseAutoModelClass._from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, task, from_hf_hub, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m only supports the following classes: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m all_model_classes)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to load \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m                     )\n\u001b[0;32m    296\u001b[0m                 logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe are using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to load \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 297\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# From local dir path\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\model_utils.py:477\u001b[0m, in \u001b[0;36mPretrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, from_hf_hub, *args, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03mCreates an instance of `PretrainedModel`. Model weights are loaded\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mby specifying name of a built-in pretrained model, or a community contributed model,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m        model = BertForSequenceClassification.from_pretrained('./my_bert/')\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconstructed_from_pretrained_config():\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_pretrained_v2(pretrained_model_name_or_path, from_hf_hub\u001b[38;5;241m=\u001b[39mfrom_hf_hub, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m resource_files \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    480\u001b[0m init_configuration \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\model_utils.py:1292\u001b[0m, in \u001b[0;36mPretrainedModel.from_pretrained_v2\u001b[1;34m(cls, pretrained_model_name_or_path, from_hf_hub, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   1291\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[1;32m-> 1292\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   1293\u001b[0m         config_path,\n\u001b[0;32m   1294\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1295\u001b[0m         return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1296\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   1297\u001b[0m         from_hf_hub\u001b[38;5;241m=\u001b[39mfrom_hf_hub,\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_dir, CONFIG_NAME)):\n\u001b[0;32m   1302\u001b[0m     config\u001b[38;5;241m.\u001b[39msave_pretrained(cache_dir)\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\configuration_utils.py:734\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, from_hf_hub, cache_dir, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;124;03mInstantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;124;03massert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m    732\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_hf_hub\u001b[39m\u001b[38;5;124m\"\u001b[39m: from_hf_hub, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir})\n\u001b[1;32m--> 734\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\configuration_utils.py:756\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    754\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_files\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n",
      "File \u001b[1;32mD:\\python\\anaconda3\\envs\\paddlenlp2.5\\lib\\site-packages\\paddlenlp\\transformers\\configuration_utils.py:827\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url_file_exists(community_url):\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(community_url, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration file<\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m> or <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLEGACY_CONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m> not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    830\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading configuration file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: configuration file<config.json> or <model_config.json> not found"
     ]
    }
   ],
   "source": [
    "text_to_image = Taskflow(\"text_to_image\")\n",
    "image_list = text_to_image(\"风阁水帘今在眼，且来先看早梅红\")\n",
    "image_list[0][0].save(\"painting-figure-1.png\")\n",
    "image_list[0][1].save(\"painting-figure-2.png\")\n",
    "image_list[0][0].argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a034cf-1b8a-4757-a479-4472f1dd1ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
